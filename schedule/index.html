<!doctype html> <html lang=en > <meta charset=UTF-8 > <meta name=viewport  content="width=device-width, initial-scale=1"> <link href="/tpm2023/css/franklin.css" rel=stylesheet > <link href="/tpm2023/css/vela.css" rel=stylesheet > <link href="/tpm2023/css/style.css" rel=stylesheet > <script src="/tpm2023/libs/vela/jquery.min.js"></script> <meta name=format-detection  content="telephone=no" /> <link rel=stylesheet  href="/tpm2023/libs/bootstrap/bootstrap.min.css"> <link href="/tpm2023/libs/fontawesome/css/fontawesome.css" rel=stylesheet > <link href="/tpm2023/libs/fontawesome/css/brands.css" rel=stylesheet > <link href="/tpm2023/libs/fontawesome/css/solid.css" rel=stylesheet > <title>TPM 2023</title> <div class="main-nav slideout-menu slideout-menu-left" id=menu > <div class=flex-container > <span class=sidebar-brand > <h3 style='font-size: 25px'>TPM 2023</h3> </span> </div> <nav class=sidebar-nav > <ul class=metismenu  id=metismenu  > <li><a href="/tpm2023/index.html">Home</a> <li><a href="/tpm2023/cfp/">Call for papers</a> <li><a href="/tpm2023/papers/">Accepted papers</a> <!-- <li><a href="/tpm2023/schedule/">Schedule</a> -- --> </ul> </nav> </div> <main id=panel  class="slidout-panel slideout-panel-left"> <div class="toggle-button hamburger hamburger--spin"> <div class=hamburger-box > <div class=hamburger-inner ></div> </div> </div> <h1 class="page title">Schedule</h1> <h2 class="page title"><small> </small></h2> <h2><center></center></h2> <hr> <div class=franklin-content ><p>The workshop will be held <strong>in person</strong> on August 4th, 2023 in Pittsburgh &#40;PA, USA&#41; at the Carnegie Mellon University &#40;Room: McKenna, Peter, and Wright Room&#41;. <br /> The workshop will be streamed via Zoom at <a href="https://tinyurl.com/UAI23MPW">this link</a>. The online poster session will take place via Zoom at the same link. Please, refer to the UAI conference instructions and contact the UAI online chairs for any issues.</p> <h1 id=workshop_schedule ><a href="#workshop_schedule" class=header-anchor >Workshop Schedule</a></h1> <table><tr><th align=right >Time<th align=right >Description<tr><td align=right >9:00 – 9:10 am<td align=right >Welcome &amp; Best Paper Awards<tr><td align=right >9:10 – 9:35 am<td align=right >Spotlight Presentations &#40;part 1&#41;<tr><td align=right >9:35 – 10:00 am<td align=right >Contributed Talk<tr><td align=right >10:00 – 10:30 am<td align=right >Virtual Poster Session I &amp; Coffee Break<tr><td align=right >10:30 – 11:30 am<td align=right >Bayesian Learning Rule <br/> Speaker: <em>Emtiyaz Khan</em><tr><td align=right >11:30 – 12:30 pm<td align=right >Tractable Molecule Generation and Beyond with Transformers <br/> Speaker: <em>Jakub M. Tomczak</em><tr><td align=right >12:30 – 2:00 pm<td align=right >Lunch Break<tr><td align=right >2:00 – 3:00 pm<td align=right >Black Box Variational Inference with a Deterministic Objective: Faster, More Accurate, and Even More Black Box <br/> Speaker: <em>Tamara Broderick</em><tr><td align=right >3:00 – 3:25 am<td align=right >Spotlight Presentations &#40;part 2&#41;<tr><td align=right >3:25 – 3:50 pm<td align=right >Contributed Talk<tr><td align=right >3:50 – 4:30 pm<td align=right >Virtual Poster Session II &amp; Coffee Break<tr><td align=right >4:30 – 6:30 pm<td align=right >In-person Poster Session &amp; Virtual Poster Session II</table> <h1 id=invited_talks ><a href="#invited_talks" class=header-anchor >Invited Talks</a></h1> <ul> <li> <h2> Black Box Variational Inference with a Deterministic Objective: Faster, More Accurate, and Even More Black Box </h2> <p><strong>Tamara Broderick</strong> (MIT, USA) <p/> <p><strong>Abstract: </strong>Automatic differentiation variational inference (ADVI) offers fast and easy-to-use posterior approximation in multiple modern probabilistic programming languages. However, its stochastic optimizer lacks clear convergence criteria and requires tuning parameters. Moreover, ADVI inherits the poor uncertainty estimates of mean-field variational Bayes (MFVB). We introduce 'deterministic ADVI' (D-ADVI) to solve these issues. In particular, we replace the intractable MFVB objective with a Monte Carlo approximation; subsequently fixing the Monte Carlo draws allows the use of off-the-shelf deterministic optimization tools. We show that D-ADVI reliably finds good solutions with default settings (unlike ADVI) and is faster and more accurate than ADVI. Moreover, unlike ADVI, D-ADVI is amenable to linear response corrections, yielding more accurate posterior covariance estimates. We demonstrate the benefits of D-ADVI on a variety of real-world problems. <p/> <div class=text-muted ><p><strong>Bio: </strong>Tamara Broderick is an Associate Professor in the Department of Electrical Engineering and Computer Science at MIT. She is a member of the MIT Laboratory for Information and Decision Systems (LIDS), the MIT Statistics and Data Science Center, and the Institute for Data, Systems, and Society (IDSS). She completed her Ph.D. in Statistics at the University of California, Berkeley in 2014. Previously, she received an AB in Mathematics from Princeton University (2007), a Master of Advanced Study for completion of Part III of the Mathematical Tripos from the University of Cambridge (2008), an MPhil by research in Physics from the University of Cambridge (2009), and an MS in Computer Science from the University of California, Berkeley (2013). Her recent research has focused on developing and analyzing models for scalable Bayesian machine learning. She has been awarded selection to the COPSS Leadership Academy (2021), an Early Career Grant (ECG) from the Office of Naval Research (2020), an AISTATS Notable Paper Award (2019), an NSF CAREER Award (2018), a Sloan Research Fellowship (2018), an Army Research Office Young Investigator Program (YIP) award (2017), Google Faculty Research Awards, an Amazon Research Award, the ISBA Lifetime Members Junior Researcher Award, the Savage Award (for an outstanding doctoral dissertation in Bayesian theory and methods), the Evelyn Fix Memorial Medal and Citation (for the Ph.D. student on the Berkeley campus showing the greatest promise in statistical research), the Berkeley Fellowship, an NSF Graduate Research Fellowship, a Marshall Scholarship, and the Phi Beta Kappa Prize (for the graduating Princeton senior with the highest academic average). <p/></div> <li> <h2> TBA </h2> <p><strong>Emtiyaz Khan</strong> (RIKEN-AIP, Japan) <p/> <p><strong>Abstract: </strong>TBA <p/> <div class=text-muted ><p><strong>Bio: </strong>Emtiyaz Khan (also known as Emti) is a (tenured) team leader at the RIKEN center for Advanced Intelligence Project (AIP) in Tokyo where he leads the Approximate Bayesian Inference Team. Previously, he was a postdoc and then a scientist at Ecole Polytechnique Fédérale de Lausanne (EPFL), where he also taught two large machine learning courses and received a teaching award. He finished his PhD in machine learning from University of British Columbia in 2012. The main goal of Emti’s research is to understand the principles of learning from data and use them to develop algorithms that can learn like living beings. For more than 10 years, his work has focused on developing Bayesian methods that could lead to such fundamental principles. The approximate Bayesian inference team now continues to use these principles, as well as derive new ones, to solve real-world problems. <p/></div> <li> <h2> TBA </h2> <p><strong>Jakub Tomczak</strong> (TU/e, NL) <p/> <p><strong>Abstract: </strong>TBA <p/> <div class=text-muted ><p><strong>Bio: </strong>TBA <p/></div> </ul> <div class=page-foot > <a href="http://creativecommons.org/licenses/by-sa/4.0/">CC BY-SA 4.0</a> Last modified: August 01, 2023. </div> </div> </main> <script src="/tpm2023/libs/vela/metisMenu.min.js"></script> <script src="/tpm2023/libs/vela/slideout.min.js"></script>